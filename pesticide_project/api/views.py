# path of this code : pesticide_project/api/views.py

from rest_framework import viewsets, status
from rest_framework.decorators import action
from rest_framework.response import Response
from rest_framework.permissions import AllowAny, IsAuthenticated
from rest_framework.exceptions import ValidationError
from django.db.models import Q, Count, Case, When
from django.utils import timezone
from datetime import timedelta
from .serializers import UserSerializer
from .models import User, SearchLog, FoodCategory
from rest_framework.filters import SearchFilter
from .models import LimitConditionCode, PesticideLimit, PesticideDetail
from .serializers import LimitConditionCodeSerializer, PesticideLimitSerializer
from django.http import HttpResponse
from django.http import JsonResponse

from django.contrib.auth import get_user_model
from django.views.decorators.csrf import csrf_exempt

class UserViewSet(viewsets.ModelViewSet):
    queryset = User.objects.all()
    serializer_class = UserSerializer

    def get_permissions(self):
        if self.action in ['create', 'signup']:
            return [AllowAny()]
        return [IsAuthenticated()]

    @action(detail=False, methods=['post'])
    def signup(self, request):
        serializer = self.get_serializer(data=request.data)
        if serializer.is_valid():
            serializer.save()
            return Response({
                'message': 'íšŒì›ê°€ì…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
                'user': serializer.data
            }, status=status.HTTP_201_CREATED)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

    @action(detail=False, methods=['get'])
    def me(self, request):
        serializer = self.get_serializer(request.user)
        return Response(serializer.data)


class LimitConditionCodeViewSet(viewsets.ReadOnlyModelViewSet):
    queryset = LimitConditionCode.objects.all()
    serializer_class = LimitConditionCodeSerializer
    pass

def format_log_message(type, **kwargs):
    time = timezone.now().strftime('%Y-%m-%d %H:%M:%S')
    if type == 'search':
        return f"ğŸ” [Search] {time}, Pesticide: {kwargs['pesticide']}, Food: {kwargs['food']}"
    elif type == 'autocomplete':
        return f"âŒ¨ï¸  [Autocomplete] {time}, Query: {kwargs['query']}"
    elif type == 'detail':
        return f"ğŸ“‹ [Detail] {time}, Pesticide: {kwargs['pesticide']}, Food: {kwargs['food']}"
    return ""


class PesticideLimitViewSet(viewsets.ReadOnlyModelViewSet):
    queryset = PesticideLimit.objects.all()
    serializer_class = PesticideLimitSerializer
    filter_backends = [SearchFilter]
    search_fields = ['pesticide_name_kr', 'pesticide_name_en', 'food_name']

    def list(self, request):
        pesticide = request.query_params.get('pesticide', '').strip()
        food = request.query_params.get('food', '').strip()
        get_all_foods = request.query_params.get('getAllFoods', '').lower() == 'true'

        # ê²€ìƒ‰ ë¡œê·¸ ì¶œë ¥
        if pesticide and food:
            print(format_log_message('search', pesticide=pesticide, food=food))

        pesticide_query = Q(pesticide_name_kr__icontains=pesticide) | Q(pesticide_name_en__icontains=pesticide)
        # queryset = self.queryset.filter(pesticide_query)
        queryset = self.queryset.filter(pesticide_query).select_related('condition_code')

        if get_all_foods and pesticide:
            queryset = queryset.order_by('food_name')
            serializer = self.get_serializer(queryset, many=True)
            return Response(serializer.data)

        if not pesticide or not food:
            raise ValidationError("Both pesticide and food parameters are required")

        pesticide_exists = queryset.exists()

        # ë¨¼ì € ì§ì ‘ ë§¤ì¹­ ì‹œë„
        direct_matches = queryset.filter(food_name__iexact=food).order_by(
            Case(
                When(food_name__iexact=food, then=0),
                default=1
            ),
            'food_name'
        )

        if direct_matches.exists():
            serializer = self.get_serializer(direct_matches, many=True)
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ë¡œê¹…
            self._log_search(pesticide, food, direct_matches.count())
            return Response(serializer.data)

        # ì§ì ‘ ë§¤ì¹­ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ FoodCategory í™•ì¸
        try:
            category = FoodCategory.objects.get(food_name__iexact=food)
            if category.sub_category:
                sub_matches = queryset.filter(food_name__iexact=category.sub_category)
                if sub_matches.exists():
                    for match in sub_matches:
                        match.matching_type = 'sub'
                        match.original_food_name = food
                    serializer = self.get_serializer(sub_matches, many=True)
                    return Response(serializer.data)

            if category.main_category:
                main_matches = queryset.filter(food_name__iexact=category.main_category)
                if main_matches.exists():
                    for match in main_matches:
                        match.matching_type = 'main'
                        match.original_food_name = food
                    serializer = self.get_serializer(main_matches, many=True)
                    return Response(serializer.data)

        except FoodCategory.DoesNotExist:
            pass

        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°ë„ ë¡œê¹… (results_count=0)
        self._log_search(pesticide, food, 0)

        pesticide_info = queryset.first()
        return Response({
            "error": "no_match",
            "error_type": "not_permitted",
            "message": f"'{pesticide}'ì€(ëŠ”) '{food}'ì— ì‚¬ìš©ì´ í—ˆê°€ë˜ì§€ ì•Šì€ ë†ì•½ì„±ë¶„ì…ë‹ˆë‹¤.",
            "searched_pesticide": pesticide,
            "pesticide_name_kr": pesticide_info.pesticide_name_kr if pesticide_info else pesticide,
            "pesticide_name_en": pesticide_info.pesticide_name_en if pesticide_info else pesticide,
            "searched_food": food
        }, status=status.HTTP_404_NOT_FOUND)

    @action(detail=False, methods=['GET'], url_path='detail')
    def get_detail(self, request):
        try:
            pesticide = request.query_params.get('pesticide')
            food = request.query_params.get('food')

            # ìƒì„¸ì •ë³´ ë¡œê·¸ ì¶œë ¥
            if pesticide and food:
                print(format_log_message('detail', pesticide=pesticide, food=food))

            # ê¸°ë³¸ ì¿¼ë¦¬ ì‹¤í–‰
            details = PesticideDetail.objects.filter(
                prdlst_kor_nm__icontains=pesticide,
                crops_nm__icontains=food
            ).order_by('-prdlst_reg_dt')

            # ë†ì•½ì„±ë¶„ëª…ìœ¼ë¡œ ê·¸ë£¹í™”ëœ ë°ì´í„° êµ¬ì„±
            grouped_data = {}
            for detail in details:
                prdlst_kor_nm = detail.prdlst_kor_nm
                if prdlst_kor_nm not in grouped_data:
                    grouped_data[prdlst_kor_nm] = {
                        'pesticide_name': prdlst_kor_nm,
                        'products': []
                    }

                grouped_data[prdlst_kor_nm]['products'].append({
                    'brand_name': detail.brnd_nm,
                    'purpose': detail.prpos_dvs_cd_nm,
                    'target_pest': detail.sickns_hlsct_nm_weeds_nm,
                    'company': detail.cpr_nm,
                    'reg_date': detail.prdlst_reg_dt
                })

            # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            result = list(grouped_data.values())
            return Response(result)

        except Exception as e:
            print(f"Error in get_detail: {str(e)}")
            return Response(
                {'error': str(e)},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    def _log_search(self, pesticide, food, results_count):
        """ê²€ìƒ‰ ë¡œê·¸ë¥¼ ê¸°ë¡í•˜ëŠ” ë‚´ë¶€ ë©”ì„œë“œ"""
        try:
            # í´ë¼ì´ì–¸íŠ¸ IP ê°€ì ¸ì˜¤ê¸°
            x_forwarded_for = self.request.META.get('HTTP_X_FORWARDED_FOR')
            if x_forwarded_for:
                ip = x_forwarded_for.split(',')[0].strip()
            else:
                ip = self.request.META.get('REMOTE_ADDR')

            # User Agent ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            user_agent = self.request.META.get('HTTP_USER_AGENT', '')

            # ê²€ìƒ‰ì–´ ì¡°í•©
            search_term = f"ë†ì•½: {pesticide}, ì‹í’ˆ: {food}"

            # ê²€ìƒ‰ ë¡œê·¸ ì €ì¥
            SearchLog.objects.create(
                search_term=search_term,
                pesticide_term=pesticide,
                food_term=food,
                results_count=results_count,
                ip_address=ip,
                user_agent=user_agent
            )

            print(f"Search logged - IP: {ip}, Terms: {search_term}, Results: {results_count}")

        except Exception as e:
            print(f"Error logging search: {str(e)}")

    @action(detail=False, methods=['GET'])
    def search_statistics(self, request):
        """ê²€ìƒ‰ í†µê³„ë¥¼ ì œê³µí•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸"""
        # ìµœê·¼ 7ì¼ê°„ì˜ ë°ì´í„°ë§Œ ì¡°íšŒ
        last_week = timezone.now() - timedelta(days=7)

        stats = {
            'total_searches': SearchLog.objects.count(),
            'unique_terms': SearchLog.objects.values('search_term').distinct().count(),
            'recent_searches': SearchLog.objects.filter(
                timestamp__gte=last_week
            ).count(),
            'popular_terms': list(SearchLog.objects.values('search_term')
                                  .annotate(count=Count('search_term'))
                                  .order_by('-count')[:10]
                                  ),
            'daily_searches': list(SearchLog.objects.filter(
                timestamp__gte=last_week
            ).values('timestamp__date')
                                   .annotate(count=Count('id'))
                                   .order_by('timestamp__date')
                                   )
        }

        return Response(stats)

    @action(detail=False, methods=['GET'])
    def autocomplete(self, request):
        query = request.query_params.get('query', '').strip()

        # ìë™ì™„ì„± ë¡œê·¸ ì¶œë ¥
        if len(query) >= 2:
            print(format_log_message('autocomplete', query=query))

        if len(query) < 2:
            return Response([])

        results = PesticideLimit.objects.filter(
            Q(pesticide_name_kr__icontains=query) |
            Q(pesticide_name_en__icontains=query)
        ).values('pesticide_name_kr', 'pesticide_name_en').distinct()[:10]

        return Response(results)

    @action(detail=False, methods=['GET'])
    def food_autocomplete(self, request):
        query = request.query_params.get('query', '').strip()

        # ìë™ì™„ì„± ë¡œê·¸ ì¶œë ¥
        if len(query) >= 1: # í•œê¸€ë§Œ ì…ë ¥í•´ë„ ìë™ì™„ì„± ì‹œë„
            print(format_log_message('autocomplete', query=query))

        if len(query) < 1:
            return Response([])

        # PesticideLimit ëª¨ë¸ì—ì„œ food_name í•„ë“œë¥¼ ê²€ìƒ‰í•˜ì—¬ ìë™ì™„ì„± ê²°ê³¼ ì œê³µ
        results = PesticideLimit.objects.filter(
            food_name__icontains=query
        ).values_list('food_name', flat=True).distinct().order_by('food_name')[:10]

        return Response(list(results))

    @action(detail=False, methods=['GET'])
    def find_similar_foods(self, request):
        """íŒŒì‹±ëœ í’ˆëª©ëª…ê³¼ ìœ ì‚¬í•œ DB í’ˆëª©ë“¤ì„ ê²€ìƒ‰í•˜ì—¬ ë°˜í™˜"""
        parsed_food = request.query_params.get('food', '').strip()
        
        if not parsed_food:
            return Response({'error': 'ê²€ìƒ‰í•  í’ˆëª©ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.'}, status=status.HTTP_400_BAD_REQUEST)
        
        # 1. ì •í™•í•œ ë§¤ì¹­ ë¨¼ì € ì‹œë„
        exact_match = PesticideLimit.objects.filter(
            food_name__iexact=parsed_food
        ).values_list('food_name', flat=True).distinct().first()
        
        if exact_match:
            return Response({
                'exact_match': True,
                'food_name': exact_match
            })
        
        # 2. ë¶€ë¶„ ë§¤ì¹­ìœ¼ë¡œ ìœ ì‚¬í•œ í’ˆëª©ë“¤ ì°¾ê¸°
        similar_foods = []
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ (ê³µë°±, íŠ¹ìˆ˜ë¬¸ìë¡œ ë¶„ë¦¬)
        import re
        keywords = re.findall(r'[ê°€-í£a-zA-Z]+', parsed_food)
        
        for keyword in keywords:
            if len(keyword) >= 2:  # 2ê¸€ì ì´ìƒ í‚¤ì›Œë“œë§Œ ê²€ìƒ‰
                matches = PesticideLimit.objects.filter(
                    food_name__icontains=keyword
                ).values_list('food_name', flat=True).distinct()[:20]
                
                for match in matches:
                    if match not in similar_foods:
                        similar_foods.append(match)
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        similar_foods = sorted(list(set(similar_foods)))[:10]
        
        return Response({
            'exact_match': False,
            'parsed_food': parsed_food,
            'similar_foods': similar_foods
        })

    @action(detail=False, methods=['GET'])
    def search_logs(self, request):
        """ê²€ìƒ‰ ë¡œê·¸ë¥¼ ì¡°íšŒí•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸"""
        # ê´€ë¦¬ìë§Œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
        if not request.user.is_staff:
            return Response({"error": "ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤."}, status=status.HTTP_403_FORBIDDEN)

        try:
            # ìµœê·¼ 100ê°œ ë¡œê·¸ ì¡°íšŒ
            logs = SearchLog.objects.all().order_by('-timestamp')[:100]

            data = [{
                'timestamp': log.timestamp,
                'ip_address': log.ip_address,
                'search_term': log.search_term,
                'pesticide_term': log.pesticide_term,
                'food_term': log.food_term,
                'results_count': log.results_count,
                'user_agent': log.user_agent
            } for log in logs]

            return Response(data)

        except Exception as e:
            return Response(
                {"error": f"ë¡œê·¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

def index(request):
    """ë£¨íŠ¸ ê²½ë¡œì— ì ‘ê·¼í•  ë•Œ í‘œì‹œë˜ëŠ” ê¸°ë³¸ ì¸ë±ìŠ¤ ë·°"""
    return HttpResponse("Welcome to the pesticide monitoring application!")

def health_check(request):
    return JsonResponse({"status": "ok"}, status=200)
